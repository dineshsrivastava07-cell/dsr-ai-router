#!/usr/bin/env bash
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  Claude CLI â€” Full 3-Tier Routing                            â•‘
# â•‘  T1: Qwen3-Coder:480B (Ollama)  â†’ haiku model names         â•‘
# â•‘  T2: Gemini CLI (Google OAuth)   â†’ sonnet model names        â•‘
# â•‘  T3: Claude (account auth)       â†’ opus model names          â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ROUTER_DIR="$HOME/.claude-router"
PROXY_PORT=4000
BRIDGE_PORT=4001
PROXY_PID="$ROUTER_DIR/proxy/proxy.pid"
BRIDGE_PID="$ROUTER_DIR/proxy/bridge.pid"
PROXY_LOG="$ROUTER_DIR/logs/proxy.log"
BRIDGE_LOG="$ROUTER_DIR/logs/gemini-bridge.log"
PYTHON="$ROUTER_DIR/venv/bin/python3"

# â”€â”€ 1. Ensure Ollama is running â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ! curl -sf http://localhost:11434/api/tags >/dev/null 2>&1; then
  echo "  âš¡ Starting Ollama..."
  nohup ollama serve >"$ROUTER_DIR/logs/ollama.log" 2>&1 &
  for i in {1..15}; do
    sleep 1
    curl -sf http://localhost:11434/api/tags >/dev/null 2>&1 && break
  done
  echo "  âœ… Ollama ready"
else
  echo "  âœ… Ollama running"
fi

# â”€â”€ 2. Start Gemini bridge (T2, port 4001) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ! curl -sf http://localhost:$BRIDGE_PORT/health >/dev/null 2>&1; then
  echo "  âš¡ Starting Gemini bridge (T2)..."
  GOOGLE_GENAI_USE_GCA=true nohup "$PYTHON" \
    "$ROUTER_DIR/proxy/gemini-bridge/gemini_bridge.py" \
    >"$BRIDGE_LOG" 2>&1 &
  echo $! > "$BRIDGE_PID"
  sleep 2
  curl -sf http://localhost:$BRIDGE_PORT/health >/dev/null 2>&1 \
    && echo "  âœ… Gemini bridge ready" \
    || echo "  âš ï¸  Gemini bridge slow â€” check $BRIDGE_LOG"
else
  echo "  âœ… Gemini bridge running"
fi

# â”€â”€ 3. Start custom router proxy (port 4000) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ! curl -sf http://localhost:$PROXY_PORT/health >/dev/null 2>&1; then
  echo "  âš¡ Starting routing proxy (port $PROXY_PORT)..."
  GOOGLE_GENAI_USE_GCA=true nohup "$PYTHON" \
    "$ROUTER_DIR/proxy/router_proxy.py" \
    >"$PROXY_LOG" 2>&1 &
  echo $! > "$PROXY_PID"
  for i in {1..10}; do
    sleep 1
    curl -sf http://localhost:$PROXY_PORT/health >/dev/null 2>&1 && break
  done
  echo "  âœ… Proxy ready (PID: $(cat $PROXY_PID))"
else
  echo "  âœ… Proxy running"
fi

# â”€â”€ Banner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®"
echo "  â”‚  ðŸ¤–  Claude CLI  +  3-Tier AI Router                 â”‚"
echo "  â”‚                                                       â”‚"
echo "  â”‚  T1 â†’ Qwen3-Coder:480B  (haiku  â†’ Ollama local)     â”‚"
echo "  â”‚  T2 â†’ Gemini 2.5-Pro    (sonnet â†’ Google OAuth)      â”‚"
echo "  â”‚  T3 â†’ Claude            (opus   â†’ last resort)       â”‚"
echo "  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯"
echo ""

# â”€â”€ Launch Claude CLI via proxy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export ANTHROPIC_BASE_URL="http://localhost:$PROXY_PORT"
export GOOGLE_GENAI_USE_GCA=true
unset ANTHROPIC_API_KEY

exec claude "$@"
